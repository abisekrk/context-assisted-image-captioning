# Training and Evaluation
[OFA](https://github.com/OFA-Sys/OFA) is a unified multimodal pretrained model that multiple vision and language tasks. We add additional pretraining tasks that focus on using context of the images during training.

We make use of the original code repository of [OFA](https://github.com/OFA-Sys/OFA/tree/main) with changes to accommodate the new pretraining tasks. We have added a fork of the original repository with our changes to aid reproducability.

# Requirements
* python 3.7.4
* pytorch 1.8.1
* torchvision 0.9.1
* JAVA 1.8 (for COCO evaluation)
<br></br>

# Related Codebase
* [OFA](https://github.com/OFA-Sys/OFA)
* [Fairseq](https://github.com/pytorch/fairseq)
* [taming-transformers](https://github.com/CompVis/taming-transformers)
<br></br>





